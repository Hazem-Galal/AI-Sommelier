{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4985cadb",
   "metadata": {},
   "source": [
    "# AI Sommelier - Wine Recommendation Agent\n",
    "\n",
    "This notebook implements an AI Sommelier using OpenAI's Assistants API v2 with file_search capability.\n",
    "\n",
    "## Features\n",
    "- **Personalized wine recommendations** based on food, taste preferences, budget, and occasion\n",
    "- **PDF-grounded responses** - All recommendations cite a wine catalog PDF\n",
    "- **Stateful conversations** - Multi-turn dialogue with context preservation\n",
    "- **Classic pairing principles** - Matches intensity, balances acidity, fat, spice, sweetness, and tannin\n",
    "\n",
    "## Setup Requirements\n",
    "1. **OpenAI API Key**: Store in Google Colab Secrets as `OPENAI_API_KEY`\n",
    "   - Click the key icon üîë in the left sidebar\n",
    "   - Add new secret: Name = `OPENAI_API_KEY`, Value = your API key\n",
    "2. **Wine PDF**: Upload `Vinhos baba d_urso.pdf` to this Colab session or Google Drive\n",
    "3. **First-time setup**: Run all cells in order to create the vector store\n",
    "4. **Subsequent uses**: You can reuse the vector store ID to avoid re-indexing\n",
    "\n",
    "## Cost Estimates\n",
    "- Vector store storage: ~$0.10/GB/day\n",
    "- File search queries: ~$0.03/GB per query\n",
    "- Model usage: Standard GPT-4o rates apply\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7f775",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Installation & Imports\n",
    "\n",
    "Install required packages and import dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q openai python-dotenv\n",
    "\n",
    "# Import dependencies\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import json\n",
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "# Display versions for reproducibility\n",
    "import openai\n",
    "print(f\"OpenAI SDK version: {openai.__version__}\")\n",
    "print(\"‚úÖ Packages installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaa2d82",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Configuration & API Key Setup\n",
    "\n",
    "Initialize the OpenAI client with your API key from Colab Secrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01751377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve API key from Colab Secrets\n",
    "try:\n",
    "    api_key = userdata.get('OPENAI_API_KEY')\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key is empty\")\n",
    "    print(\"‚úÖ API key retrieved from Colab Secrets\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error: Could not retrieve OPENAI_API_KEY from Colab Secrets\")\n",
    "    print(\"Please add your OpenAI API key to Colab Secrets:\")\n",
    "    print(\"  1. Click the key icon üîë in the left sidebar\")\n",
    "    print(\"  2. Add new secret: Name = 'OPENAI_API_KEY', Value = your API key\")\n",
    "    raise\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Configuration constants\n",
    "MODEL = \"gpt-4o\"  # Best model for file_search capability\n",
    "TEMPERATURE = 0.7  # Balanced creativity and consistency\n",
    "MAX_TOKENS = 2000  # Maximum response length\n",
    "\n",
    "print(f\"‚úÖ OpenAI client initialized with model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f12d20",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Vector Store Setup (One-Time)\n",
    "\n",
    "Upload the wine catalog PDF and create a vector store for file_search.\n",
    "\n",
    "**IMPORTANT**: \n",
    "- First run: Leave `VECTOR_STORE_ID = None` to create a new vector store\n",
    "- After creation, copy the printed ID and paste it here to reuse in future sessions\n",
    "- This avoids re-indexing costs and setup time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76dea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure vector store ID (set to None for first-time setup)\n",
    "VECTOR_STORE_ID = None  # Replace with your vector store ID after first run, e.g., \"vs_abc123...\"\n",
    "\n",
    "# PDF file path - Update this to match your PDF location\n",
    "WINE_PDF_PATH = \"/content/Vinhos baba d_urso.pdf\"  # Default Colab upload location\n",
    "# Alternative: Google Drive path after mounting\n",
    "# WINE_PDF_PATH = \"/content/drive/MyDrive/Vinhos baba d_urso.pdf\"\n",
    "\n",
    "if VECTOR_STORE_ID is None:\n",
    "    print(\"üîÑ Creating new vector store...\")\n",
    "    \n",
    "    # Check if PDF exists\n",
    "    if not os.path.exists(WINE_PDF_PATH):\n",
    "        print(f\"‚ùå Error: PDF not found at {WINE_PDF_PATH}\")\n",
    "        print(\"\\nPlease upload 'Vinhos baba d_urso.pdf' using one of these methods:\")\n",
    "        print(\"  1. Drag and drop the PDF into the Files panel (left sidebar)\")\n",
    "        print(\"  2. Mount Google Drive and update WINE_PDF_PATH variable\")\n",
    "        print(\"\\nTo mount Google Drive, run: from google.colab import drive; drive.mount('/content/drive')\")\n",
    "        raise FileNotFoundError(f\"Wine catalog PDF not found at {WINE_PDF_PATH}\")\n",
    "    \n",
    "    # Create vector store\n",
    "    vector_store = client.beta.vector_stores.create(\n",
    "        name=\"Wine Catalog - Vinhos Baba d'Urso\"\n",
    "    )\n",
    "    \n",
    "    # Upload PDF to vector store\n",
    "    with open(WINE_PDF_PATH, \"rb\") as pdf_file:\n",
    "        file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "            vector_store_id=vector_store.id,\n",
    "            files=[pdf_file]\n",
    "        )\n",
    "    \n",
    "    print(f\"‚úÖ Vector store created successfully!\")\n",
    "    print(f\"\\nüìã SAVE THIS ID FOR FUTURE USE:\")\n",
    "    print(f\"   VECTOR_STORE_ID = \\\"{vector_store.id}\\\"\")\n",
    "    print(f\"\\nFile batch status: {file_batch.status}\")\n",
    "    print(f\"Files processed: {file_batch.file_counts.completed}/{file_batch.file_counts.total}\")\n",
    "    \n",
    "    VECTOR_STORE_ID = vector_store.id\n",
    "else:\n",
    "    print(f\"‚ôªÔ∏è  Reusing existing vector store: {VECTOR_STORE_ID}\")\n",
    "    try:\n",
    "        vector_store = client.beta.vector_stores.retrieve(VECTOR_STORE_ID)\n",
    "        print(f\"‚úÖ Vector store retrieved: {vector_store.name}\")\n",
    "        print(f\"   Files: {vector_store.file_counts.completed}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error retrieving vector store: {e}\")\n",
    "        print(\"   Set VECTOR_STORE_ID = None to create a new one\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566c83a",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ AI Sommelier Agent Definition\n",
    "\n",
    "Create the sommelier assistant with instructions and file_search capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent instructions from prompt.txt\n",
    "SOMMELIER_INSTRUCTIONS = \"\"\"You are an expert AI Sommelier with formal wine education and restaurant-level tasting experience.\n",
    "Your role is to guide users through personalized wine recommendations, pairings, education, and virtual tastings.\n",
    "You have access to a knowledge base built from a PDF containing wine catalog entries, tasting notes, regions, grape varieties, pricing, and pairing guidance.\n",
    "You MUST ground all wine facts and recommendations in passages retrieved from the PDF via file_search.\n",
    "\n",
    "PRIMARY OBJECTIVE\n",
    "Provide accurate, practical wine recommendations tailored to the user's food, taste preferences, budget, and occasion.\n",
    "\n",
    "RETRIEVAL RULES\n",
    "- Always use file_search before recommending wines.\n",
    "- Base recommendations ONLY on information present in retrieved PDF content.\n",
    "- Do NOT invent wines, vintages, regions, prices, or tasting notes.\n",
    "- If the PDF lacks required info, say what's missing and ask exactly ONE concise follow-up question.\n",
    "\n",
    "RECOMMENDATION FORMAT\n",
    "Recommend 2‚Äì4 options. For EACH wine include:\n",
    "- Wine name (exactly as in the PDF)\n",
    "- Country / region\n",
    "- Grape variety or blend\n",
    "- Style profile: body, acidity, tannin, sweetness\n",
    "- Why it matches the user's food/preferences\n",
    "- Serving temperature\n",
    "- Optional: decanting/glassware note ONLY if supported by the PDF\n",
    "\n",
    "PAIRING LOGIC\n",
    "Apply classic pairing principles:\n",
    "- Match intensity (light with light, bold with bold)\n",
    "- Balance acidity, fat, spice, sweetness, and tannin\n",
    "- Spicy food: prioritize acidity, aromatics, and lower alcohol (if supported)\n",
    "- Fatty/grilled dishes: structure/tannin or acidity as appropriate\n",
    "\n",
    "CONSTRAINTS\n",
    "- Respect budget strictly.\n",
    "- Respect exclusions (e.g., \"no sweet\", \"no heavy oak\", allergies).\n",
    "- Keep the tone polished and concise.\n",
    "- Do not mention embeddings, vectors, or internal tooling.\n",
    "\n",
    "FALLBACK\n",
    "If no exact match exists:\n",
    "- Recommend the closest stylistic alternatives found in the PDF\n",
    "- Explain the limitation of the source material\n",
    "- Ask ONE targeted question\n",
    "\n",
    "OUTPUT STRUCTURE\n",
    "- 1‚Äì2 sentence summary\n",
    "- Bullet list of recommendations\n",
    "- Optional single follow-up question (only if needed)\n",
    "\"\"\"\n",
    "\n",
    "# Create the assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"AI Sommelier\",\n",
    "    instructions=SOMMELIER_INSTRUCTIONS,\n",
    "    model=MODEL,\n",
    "    temperature=TEMPERATURE,\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    tool_resources={\n",
    "        \"file_search\": {\n",
    "            \"vector_store_ids\": [VECTOR_STORE_ID]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ AI Sommelier assistant created\")\n",
    "print(f\"   Assistant ID: {assistant.id}\")\n",
    "print(f\"   Model: {assistant.model}\")\n",
    "print(f\"   Tools: {[tool.type for tool in assistant.tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa288f5",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Session Management Functions\n",
    "\n",
    "Functions to manage conversation threads and retrieve responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2599555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable to store thread ID\n",
    "thread_id = None\n",
    "\n",
    "def create_conversation():\n",
    "    \"\"\"Create a new conversation thread.\"\"\"\n",
    "    global thread_id\n",
    "    thread = client.beta.threads.create()\n",
    "    thread_id = thread.id\n",
    "    print(f\"üÜï New conversation started (Thread ID: {thread_id})\")\n",
    "    return thread_id\n",
    "\n",
    "def send_message(message):\n",
    "    \"\"\"Send a message and get the sommelier's response.\"\"\"\n",
    "    global thread_id\n",
    "    \n",
    "    if thread_id is None:\n",
    "        create_conversation()\n",
    "    \n",
    "    # Add user message to thread\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=message\n",
    "    )\n",
    "    \n",
    "    # Create and poll the run\n",
    "    run = client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant.id,\n",
    "        timeout=60  # 60 second timeout\n",
    "    )\n",
    "    \n",
    "    # Check run status\n",
    "    if run.status == 'completed':\n",
    "        return get_response()\n",
    "    elif run.status == 'failed':\n",
    "        return f\"‚ùå Error: Run failed - {run.last_error}\"\n",
    "    elif run.status == 'expired':\n",
    "        return \"‚ùå Error: Request timed out. Please try again.\"\n",
    "    else:\n",
    "        return f\"‚ùå Unexpected status: {run.status}\"\n",
    "\n",
    "def get_response():\n",
    "    \"\"\"Retrieve the latest assistant response from the thread.\"\"\"\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread_id,\n",
    "        order=\"desc\",\n",
    "        limit=1\n",
    "    )\n",
    "    \n",
    "    if messages.data:\n",
    "        message = messages.data[0]\n",
    "        if message.role == \"assistant\":\n",
    "            return format_response(message)\n",
    "    \n",
    "    return \"No response received.\"\n",
    "\n",
    "def format_response(message):\n",
    "    \"\"\"Format the assistant's response, including file_search citations.\"\"\"\n",
    "    response_text = \"\"\n",
    "    citations = []\n",
    "    \n",
    "    # Extract text and annotations\n",
    "    for content in message.content:\n",
    "        if content.type == \"text\":\n",
    "            text_value = content.text.value\n",
    "            annotations = content.text.annotations\n",
    "            \n",
    "            # Collect citations from file_search\n",
    "            for idx, annotation in enumerate(annotations):\n",
    "                if annotation.type == \"file_citation\":\n",
    "                    citation_num = len(citations) + 1\n",
    "                    citations.append(f\"[{citation_num}] {annotation.file_citation.quote}\")\n",
    "                    # Replace annotation with citation number\n",
    "                    text_value = text_value.replace(annotation.text, f\" [{citation_num}]\")\n",
    "            \n",
    "            response_text += text_value\n",
    "    \n",
    "    # Append citations if present\n",
    "    if citations:\n",
    "        response_text += \"\\n\\nüìö **Sources from wine catalog:**\\n\"\n",
    "        response_text += \"\\n\".join(citations)\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "def reset_conversation():\n",
    "    \"\"\"Reset the conversation to start fresh.\"\"\"\n",
    "    global thread_id\n",
    "    thread_id = None\n",
    "    print(\"üîÑ Conversation reset. Next message will start a new thread.\")\n",
    "\n",
    "def show_conversation_history():\n",
    "    \"\"\"Display the full conversation history.\"\"\"\n",
    "    if thread_id is None:\n",
    "        print(\"No active conversation.\")\n",
    "        return\n",
    "    \n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread_id,\n",
    "        order=\"asc\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CONVERSATION HISTORY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for msg in messages.data:\n",
    "        role = \"üßë You\" if msg.role == \"user\" else \"üç∑ Sommelier\"\n",
    "        content = msg.content[0].text.value if msg.content else \"[No content]\"\n",
    "        print(f\"\\n{role}:\")\n",
    "        print(content[:500] + (\"...\" if len(content) > 500 else \"\"))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"‚úÖ Session management functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f79cf10",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Interactive Chat Loop\n",
    "\n",
    "Start chatting with the AI Sommelier!\n",
    "\n",
    "### Commands:\n",
    "- Type your wine question or pairing request\n",
    "- `quit`, `exit`, or `bye` - End conversation\n",
    "- `history` - Show full conversation\n",
    "- `reset` - Start a new conversation thread\n",
    "\n",
    "### Example Queries:\n",
    "- \"Suggest a wine for grilled salmon with lemon, budget under $30\"\n",
    "- \"I want a bold red for ribeye steak, no sweet wines\"\n",
    "- \"Pair a wine with spicy Thai curry\"\n",
    "- \"What's a good Portuguese white wine for summer?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üç∑ AI Sommelier Chat - Ready to recommend wines!\\n\")\n",
    "print(\"Type 'quit' to exit, 'history' to view conversation, 'reset' to start fresh\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize conversation\n",
    "if thread_id is None:\n",
    "    create_conversation()\n",
    "\n",
    "# Main chat loop\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"\\nüßë You: \").strip()\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        # Handle commands\n",
    "        if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "            print(\"\\nüç∑ Thank you for using AI Sommelier. Cheers! ü•Ç\")\n",
    "            break\n",
    "        \n",
    "        if user_input.lower() == 'history':\n",
    "            show_conversation_history()\n",
    "            continue\n",
    "        \n",
    "        if user_input.lower() == 'reset':\n",
    "            reset_conversation()\n",
    "            create_conversation()\n",
    "            continue\n",
    "        \n",
    "        # Send message and get response\n",
    "        print(\"\\nüç∑ Sommelier: \", end=\"\")\n",
    "        print(\"(searching wine catalog...)\")\n",
    "        \n",
    "        response = send_message(user_input)\n",
    "        print(f\"\\n{response}\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nüç∑ Chat interrupted. Type 'quit' to exit properly.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        print(\"Please try again or type 'reset' to start a new conversation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a06e3fb",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Automated Testing & Examples\n",
    "\n",
    "Run automated tests to verify the sommelier's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56993199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries demonstrating agent capabilities\n",
    "test_queries = [\n",
    "    \"Suggest a wine for grilled salmon with lemon, budget under $30\",\n",
    "    \"I want a bold red for ribeye steak, no sweet wines\",\n",
    "    \"Pair a wine with spicy Thai curry\",\n",
    "    \"What Portuguese wines do you have for seafood?\",\n",
    "    \"Recommend a wine for a romantic dinner, around $40-50\"\n",
    "]\n",
    "\n",
    "# Reset conversation for clean testing\n",
    "reset_conversation()\n",
    "create_conversation()\n",
    "\n",
    "print(\"üß™ Running automated tests...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n\\nüìù TEST {i}/{len(test_queries)}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    try:\n",
    "        response = send_message(query)\n",
    "        print(f\"\\nüç∑ Response:\\n{response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    # Small delay between requests\n",
    "    if i < len(test_queries):\n",
    "        time.sleep(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c65e92",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Troubleshooting & Utilities\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**API Key Error**\n",
    "- Ensure `OPENAI_API_KEY` is added to Colab Secrets (üîë icon in sidebar)\n",
    "- Verify the key is valid and has credits\n",
    "\n",
    "**PDF Not Found**\n",
    "- Upload `Vinhos baba d_urso.pdf` to Colab session via Files panel\n",
    "- Or mount Google Drive: `from google.colab import drive; drive.mount('/content/drive')`\n",
    "- Update `WINE_PDF_PATH` variable to match PDF location\n",
    "\n",
    "**Vector Store Error**\n",
    "- If retrieval fails, set `VECTOR_STORE_ID = None` and re-run cell 3\n",
    "- Check OpenAI dashboard for vector store status\n",
    "\n",
    "**No Wine Recommendations**\n",
    "- Verify PDF contains wine information (not empty/corrupted)\n",
    "- Check if query matches content in PDF (agent can't invent wines)\n",
    "- Try broader queries if specific wines aren't found\n",
    "\n",
    "**Timeout Errors**\n",
    "- Large PDFs may take longer to search (increase timeout in `send_message`)\n",
    "- Network issues - retry the request\n",
    "\n",
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a84f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check assistant details\n",
    "def check_assistant_status():\n",
    "    \"\"\"Display current assistant configuration.\"\"\"\n",
    "    try:\n",
    "        assistant_info = client.beta.assistants.retrieve(assistant.id)\n",
    "        print(\"üìä Assistant Status:\")\n",
    "        print(f\"   ID: {assistant_info.id}\")\n",
    "        print(f\"   Name: {assistant_info.name}\")\n",
    "        print(f\"   Model: {assistant_info.model}\")\n",
    "        print(f\"   Tools: {[t.type for t in assistant_info.tools]}\")\n",
    "        print(f\"   Vector Stores: {assistant_info.tool_resources.file_search.vector_store_ids}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Check vector store details\n",
    "def check_vector_store_status():\n",
    "    \"\"\"Display vector store information.\"\"\"\n",
    "    try:\n",
    "        vs = client.beta.vector_stores.retrieve(VECTOR_STORE_ID)\n",
    "        print(\"üìö Vector Store Status:\")\n",
    "        print(f\"   ID: {vs.id}\")\n",
    "        print(f\"   Name: {vs.name}\")\n",
    "        print(f\"   Status: {vs.status}\")\n",
    "        print(f\"   Files: {vs.file_counts.completed}/{vs.file_counts.total}\")\n",
    "        print(f\"   Created: {vs.created_at}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Quick test function\n",
    "def quick_test(query=\"What wines do you have?\"):\n",
    "    \"\"\"Send a quick test query.\"\"\"\n",
    "    print(f\"Testing with query: {query}\\n\")\n",
    "    response = send_message(query)\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "print(\"‚úÖ Utility functions loaded\")\n",
    "print(\"\\nAvailable utilities:\")\n",
    "print(\"  - check_assistant_status()\")\n",
    "print(\"  - check_vector_store_status()\")\n",
    "print(\"  - quick_test('your query here')\")\n",
    "print(\"  - reset_conversation()\")\n",
    "print(\"  - show_conversation_history()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76884fc3",
   "metadata": {},
   "source": [
    "## üìñ Usage Guide\n",
    "\n",
    "### Getting Started\n",
    "1. **First Time**: Run cells 1-4 in order to set up the system\n",
    "2. **Save Vector Store ID**: After cell 3, copy the ID and paste it back for future use\n",
    "3. **Start Chatting**: Run cell 6 to begin interactive conversation\n",
    "\n",
    "### How to Ask for Recommendations\n",
    "\n",
    "**Include Key Details:**\n",
    "- **Food/Occasion**: \"Grilled salmon\", \"romantic dinner\", \"spicy curry\"\n",
    "- **Budget**: \"Under $30\", \"around $50\", \"no budget limit\"\n",
    "- **Preferences**: \"Bold reds\", \"no sweet wines\", \"crisp whites\"\n",
    "- **Constraints**: \"No oak\", \"vegetarian pairing\", \"low alcohol\"\n",
    "\n",
    "**Example Good Queries:**\n",
    "```\n",
    "Suggest a wine for grilled salmon with lemon, budget $25-35, prefer dry whites\n",
    "I'm cooking ribeye steak tonight, what bold red would pair well?\n",
    "Need a sparkling wine for celebration, around $40\n",
    "Pair a wine with spicy Thai cuisine, I don't like sweet wines\n",
    "What Portuguese wines work well with seafood?\n",
    "```\n",
    "\n",
    "### Understanding Responses\n",
    "\n",
    "The sommelier will provide:\n",
    "- **2-4 wine recommendations** from the catalog\n",
    "- **Wine details**: Name, region, grape variety, style profile\n",
    "- **Pairing rationale**: Why it matches your food/preferences\n",
    "- **Serving notes**: Temperature, decanting if needed\n",
    "- **Citations**: References to the wine catalog PDF\n",
    "\n",
    "### Advanced Features\n",
    "\n",
    "**Multi-turn Conversations:**\n",
    "```\n",
    "You: Suggest a wine for pasta with tomato sauce\n",
    "Sommelier: [recommendations]\n",
    "You: What about something more full-bodied?\n",
    "Sommelier: [adjusted recommendations based on context]\n",
    "```\n",
    "\n",
    "**Wine Education:**\n",
    "```\n",
    "Tell me about wines from the Douro region\n",
    "What's the difference between these grape varieties?\n",
    "Explain the tasting notes for [specific wine]\n",
    "```\n",
    "\n",
    "### Cost Management\n",
    "\n",
    "- **Vector Store**: ~$0.10/GB/day (minimal for small PDF)\n",
    "- **Queries**: ~$0.03/GB per search (pennies per query)\n",
    "- **Model**: Standard GPT-4o rates (~$0.01-0.03 per query)\n",
    "- **Tip**: Reuse `VECTOR_STORE_ID` to avoid re-indexing\n",
    "\n",
    "### Updating the Wine Catalog\n",
    "\n",
    "To add a new/updated PDF:\n",
    "1. Set `VECTOR_STORE_ID = None` in cell 3\n",
    "2. Update `WINE_PDF_PATH` with new PDF location\n",
    "3. Re-run cell 3 to create new vector store\n",
    "4. Save the new vector store ID\n",
    "\n",
    "---\n",
    "\n",
    "**Happy wine pairing! üç∑ü•Ç**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
